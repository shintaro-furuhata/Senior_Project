# 実験001 結果記録シート

## 実験ログ

---

### 実行1: 初回実装（単純な次元分割）

#### 基本情報
- **実行日**: YYYY-MM-DD
- **実験者**: [名前]
- **Git commit**: [コミットハッシュ]
- **Git tag**: exp002-v1.0

#### 実験設定

**データ**:
- Dataset: MNIST
- Train samples: 60,000
- Test samples: 10,000

**Baseline**:
- Encoder: Linear(784→256) → ReLU → Linear(256→128)
- Classifier: Linear(128→10)
- Epochs: 5
- Learning rate: 0.001

**Split Model**:
- Encoder: Frozen（Baselineから取得）
- Split method: 次元分割 (h[:, :64] / h[:, 64:])
- Server Networks: Linear(64→32) → ReLU
- Final Classifier: Linear(64→10)
- Epochs: 5
- Learning rate: 0.001

#### 訓練経過

**Baseline**:
```
Epoch [1/5], Loss: 0.2555
Epoch [2/5], Loss: 0.0994
Epoch [3/5], Loss: 0.0669
Epoch [4/5], Loss: 0.0520
Epoch [5/5], Loss: 0.0397
```

**Split Model**:
```
Epoch [1/5], Loss: 0.1486
Epoch [2/5], Loss: 0.0249
Epoch [3/5], Loss: 0.0203
Epoch [4/5], Loss: 0.0178
Epoch [5/5], Loss: 0.0163
```

#### 最終結果

| 評価項目 | 精度 | 期待値 | 達成 |
|---|---|---|---|
| (1) Baseline | 97.48% | >95% | ✅ |
| (2) Server A only | 95.24% | ~10% | ❌ |
| (3) Server B only | 92.25% | ~10% | ❌ |
| (4) Combined | 98.16% | ≈Baseline | ✅ |

#### 評価: ❌ 失敗

**理由**:
- Server A/B単独の精度が高すぎる（目標: ~10%、実際: 90%以上）
- 各サーバーが単独で十分な情報を持っている
- 秘匿性が確保されていない

#### 詳細分析

**1. なぜServer A単独で95%も出るのか？**

仮説：
- Encoderの中間表現h（128次元）が情報を冗長に保持
- 前半64次元（h1）だけでも分類に必要な情報が十分
- 例: 「0」という数字なら、h1に「丸い形状」、h2に「閉じた輪郭」の情報が両方含まれている

検証方法（今後）：
- [ ] h1とh2の相関を測定
- [ ] h1/h2それぞれの主成分分析
- [ ] t-SNEでh1とh2を可視化

**2. 評価方法の問題**

現在の評価：
```python
z_A_only = torch.cat([z1, torch.zeros_like(z2)], dim=1)
logits_A = final_classifier(z_A_only)
```

問題点：
- `final_classifier`は「z1とz2の両方」を前提に訓練されている
- でもz1だけで予測できてしまう
- z2を0にしても、z1の情報で十分

改善案：
- 各サーバー専用のclassifierを用意
- 訓練時に「単独では予測できない」制約を追加

**3. 情報の冗長性を数値化**

（今後測定）
- [ ] I(h1; label) ≈ ?（h1だけでどれだけ情報を持っているか）
- [ ] I(h2; label) ≈ ?
- [ ] I(h1; h2) ≈ ?（h1とh2の相互情報量）

理想値：
- I(h1; label) → 低い（単独では情報が少ない）
- I(h2; label) → 低い
- I([h1,h2]; label) → 高い（統合すると情報が回復）

#### 次のアクション

優先度順：

1. **訓練時の制約追加**（最優先）
   - [ ] 各サーバー専用classifierの追加
   - [ ] 損失関数: `loss = loss_combined - λ * (loss_A + loss_B)`
   - [ ] λパラメータのチューニング（0.1, 0.5, 1.0を試す）

2. **分割方法の改善**
   - [ ] ランダム射影による分割
   - [ ] Learned splitting（分割自体を学習）
   - [ ] PCAベースの分割

3. **可視化・分析**
   - [ ] h1, h2の分布を可視化
   - [ ] 相互情報量の測定
   - [ ] どのクラスで失敗しているか分析

#### メモ・気づき

- Encoderの訓練方法が重要（joint trainingが必要かも）
- 単純な次元分割では不十分
- MNISTは「簡単すぎる」可能性（CIFAR-10を試すべきか？）
- 情報理論的な測定が必要

#### 添付資料

- [ ] コンソール出力の完全版
- [ ] 訓練曲線のグラフ（今後追加）
- [ ] 混同行列（今後追加）

---

### 実行2: λ-privacy制約付き訓練（予定）

#### 基本情報
- **実行日**: 
- **実験者**: 
- **Git commit**: 
- **Git tag**: exp002-v2.0

#### 実験設定

（実行後に記入）

#### 訓練経過

（実行後に記入）

#### 最終結果

| 評価項目 | 精度 | 期待値 | 達成 |
|---|---|---|---|
| (1) Baseline | % | >95% | |
| (2) Server A only | % | 20-40% | |
| (3) Server B only | % | 20-40% | |
| (4) Combined | % | ≈Baseline | |

#### 評価: 

（実行後に記入）

---

### 実行3: 

（必要に応じて追加）

---

## まとめ

### 成功した設定

（今後記入）

### 失敗した設定

1. 単純な次元分割（実行1）
   - 理由: 情報の冗長性

### 学んだこと

- 中間表現の分割だけでは不十分
- 訓練時の制約が必要
- 情報理論的な測定が重要

### 次の実験への示唆

- exp003: Encoder joint training
- exp004: 異なる分割方法の比較